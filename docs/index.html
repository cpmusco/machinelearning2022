<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <!-- Custom styles -->
    <link href="style.css" rel="stylesheet">
    <link rel="icon" href="favicon.ico">
    <base target="_blank">

    <title>CS-GY 6923 Spring 2022</title>
</head>

<body>

    <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark">
        <a class="navbar-brand" href="#">CS-GY 6923</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExampleDefault"
            aria-controls="navbarsExampleDefault" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="navbarsExampleDefault">
            <ul class="navbar-nav mr-auto">
                <li class="nav-item">
                    <a class="nav-link" href="https://edstem.org/us/join/fqC9au">Ed Stem</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="https://brightspace.nyu.edu/d2l/home/173425">Brightspace</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="https://www.gradescope.com/courses/361872">Gradescope</a>
                </li>
                <!-- <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" id="dropdown01" data-toggle="dropdown" aria-haspopup="true"
                        aria-expanded="false">Previous
                        Years
                    </a>
                    <div class="dropdown-menu" aria-labelledby="dropdown01">
                        <a class="dropdown-item" href="https://www.cs.princeton.edu/~smattw/Teaching/cos521fa17.htm">2017</a>
                        <a class="dropdown-item" href="https://www.cs.princeton.edu/courses/archive/fall16/cos521/">2016</a>
                    </div>
                </li> -->
            </ul>
        </div>
    </nav>

    <main role="main">

        <!-- Main jumbotron for a primary marketing message or call to action -->
        <section class="jumbotron text-center">
            <div class="container">
                <h1 class="jumbotron-heading">NYU CS-GY 6923<br>Machine Learning</h1>

                <p class="lead text-muted">
                    A broad introduction to the exciting field of machine learning through a mixture of hands-on experience and theoretical foundations.
                </p>

                <h5 class="instructors">
                    <br/>
                    <p><b>Course Team:</b></p>

                    <div class="row">
                        <div class="col-sm">
                            <a href="https://www.chrismusco.com/"><img src="christophermusco.jpg" alt="Christopher Musco" height="150"></a>
                            <div class="role">Professor</div>
                            <a href="mailto:cmusco@nyu.edu">Christopher Musco</a>
                        </div>
                        <div class="col-sm">
                            <a href="https://wireless.engineering.nyu.edu/current-students/"><img src="ozlem.jpg" alt="Ozlem Yildiz" height="150"></a>
                            <div class="role">Course Assistant</div>
                            <a href="mailto:zy2043@nyu.edu">Ozlem Yildiz</a>
                        </div>
                        <div class="col-sm">
                            <img src="siddharth.jpg" alt="Siddharth Sagar"  height="150">
                            <div class="role">Course Assistant</div>
                            <a href="mailto:ss13973@nyu.edu">Siddharth Sagar</a>
                        </div>
                        <div class="col-sm">
                            <img src="thomas.jpg" alt="Thomas Liu"  height="150">
                            <div class="role">Course Assistant</div>
                            <a href="mailto:xl2623@nyu.edu">Thomas Liu</a>
                        </div>
                    </div>
                </h5>
            </div>
        </section>

        <div class="album py-3 bg-light">
            <div class="container">
                <div class="row">
                </div>
                <div class="row">
                    <div class="col-sm">
                        <p class="courseinfo">
                            <b>Lectures:</b>  215 Rogers Hall. Virtually via Zoom (links on Brightspace).<br>
                            <b>Professor office hours:</b> Weekly on Mondays 11am-1pm. <a href="https://nyu.zoom.us/my/cmusco">Zoom link</a>. <br> 
                            <b>Thomas office hours:</b> Weekly on Wednesdays 12-1pm. <a href="https://nyu.zoom.us/j/7460765332">Zoom link</a>. <br> 
                            <b>Siddharth office hours:</b> Weekly on Tuesdays 3-4pm. <a href=" https://nyu.zoom.us/j/95618075198">Zoom link</a>. <br> 
                            <b>Ozlem office hours:</b> Weekly on Tuesdays 12-2pm. <a href="https://nyu.zoom.us/j/94940741268">Zoom link</a>. <br> 
                        </p>
                        <p class="courseinfo">
                            <b>Syllabus:</b> <a href="syllabus.pdf"> here.</a></br>
                            <b>Grading breakdown:</b> Written Problem Sets 25%, Programming Labs (including mini-project) 25%, Midterm 20%, Final Exam 20%, Participation 10%
                        </p>

                        <p class="courseinfo">
                            <b>Ed Stem:</b> All course communicate will be via Ed, so please create an account and <a href="https://edstem.org/us/join/fqC9au">join our site.</a> All questions should also be posted to Ed (not sent via emails). We prefer that questions about lectures or homework are asked publicly, since they will often help your classmates, but Ed supports private questions for things relevant only to you.
                        </p>
                        <p class="courseinfo">
                            <b>Python and Jupyter:</b> Demos and labs in this class use Python, run through Jupyter notebooks. Jupyter lets you create and edit documents with live Python code and rich comments and images. We suggest that students run their Jupyter notebooks via Google Colaboratory, and we will share them via Colab. Uou also have the option of installing and running everything on your personal computer. Instructions can be found <a href="https://github.com/cpmusco/introml/tree/master/basic_setup">here.</a>
                        </p>

                        <!-- <p class="courseinfo">
                            <b>Git Repository:</b> Assignments and labs should be downloaded from our <a href="https://github.com/cpmusco/machinelearning2022">GitHub repo</a>. To stay organized, we suggest students access material from this repository using a git client. Instructions can be found <a href="https://github.com/cpmusco/machinelearning2022/tree/master/basic_setup">here.</a>
                        </p> -->

                        <p class="courseinfo">
                            <b>Prerequisites:</b> 
                            Modern machine learning uses a lot of math! Probably more than any other subject in computer science outside theoretical computer science. You can get pretty far with an understanding of just calculus, probability, and linear algebra, but <i>that understanding needs to be solid</i> for you to succeed in this course. Formally we require a prior course in probability or statistics. If you need to freshen up on linear algebra, this <a href="http://web.stanford.edu/class/cs246/handouts/CS246_LinAlg_review.pdf">quick reference</a> from Stanford is helpful.

                        </p>
                    </div>

                    <div class="col-sm">

                        <p class="courseinfo">
                            <b>Homework:</b> Homework (both written problems and coding labs) must be turned in to Gradescope by the specified deadline. Use the code P5D5BP to <a href="https://www.gradescope.com/courses/361872">join the class on Gradescope.</a> We do not accept late work without prior permission.<br><br>
                            
                            Labs should be turned in as <i>evaluated</i> Jupyter notebooks. Do not clear the output before turning in.
                            While not required, for written problem sets I encourage students to prepare problem sets in <a href="https://astrobites.org/2018/01/20/getting-started-with-latex/">LaTeX</a> or <a href="https://en.wikipedia.org/wiki/Markdown"> Markdown</a> (with <a href="http://support.typora.io/Math/">math support</a>.)
                            You can use this <a href="template.tex">template</a> for LaTeX. While there is a learning curve, these tools typically save students time in the end! If you do write problems by hand, scan and upload as a PDF.<br><br>
                      
                            <u>Discussion is allowed on homework, but solutions and code must be written independently</u>. See the <a href="syllabus.pdf">syllabus</a> for details. We have a zero tolerance policy for copied code or solutions: any students with duplicate or very similar material will receive a zero on the offending assignment. My advice is to <b>never share code or solutions with other students.</b>
                        </p>

                        <p class="courseinfo">
                            <b>Resources:</b> There is no textbook to purchase. I may post readings, some of which will come from the following book, which is available free online via the NYU library: 
                            <ul>
                                <li><a href="https://bobcat.library.nyu.edu/permalink/f/1c17uag/nyu_aleph008192436">An Introduction to Statistical Learning</a> by James, Witten, Hastie, and Tibshirani.</li>
                            </ul>
                            I have also found <a href="https://work.caltech.edu/lectures.html#lectures"> the lectures and notes</a> from the <a href="https://work.caltech.edu/telecourse.html">companion site</a> to the book <a href="http://work.caltech.edu/textbook.html">Learning With Data</a> (ISBN 978-1-60049-006-4) can be very helpful. This is a compact, inexpensive book if you want to purchase.
                            
                            
                        </p>
                    </div>
                </div>
            </div>
        </div>

        <div class="album py-3 bg-light">
            <div class="container">
                <table class="table">
                    <thead class="thead-dark">
                        <tr>
                            <th scope="col">Lecture #</th>
                            <th scope="col">Topic</th>
                            <th scope="col">Reading</th>
                            <th scope="col">Homework</th>
                        </tr>
                    </thead>
                    <tbody>

                        <tr class="tablesection">
                            <td colspan="4">Regression and Function Fitting</td>
                        </tr>

                        <tr class="oddrow">
                            <th scope="row">1. 1/27</th>
                            <td>Introduction to Machine Learning, Simple Linear Regression, Loss Functions</td>
                            <td>
                                <ul>
                                    <li>
                                        <a href="./lectures/lec1.pdf">Lecture 1 slides</a> <a href="./lectures/lec1_annotated.pdf">(annotated)</a>.
                                    </li>
                                    <br>


                                    <li>
                                        <b>Probability Review:</b> See this <a href="http://cs229.stanford.edu/section/cs229-prob.pdf">complete references</a> or the very good resources on <a href="https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library">Khan Academy</a>.
                                    </li>
                                    <li>
                                        <b>Linear Algebra Review:</b> <a href="http://web.stanford.edu/class/cs246/handouts/CS246_LinAlg_review.pdf">This</a> should get you started.
                                    </li>
                                </ul>
                            </td>
                            <td>
                                <ul>
                                    <li>
                                        Work through <a href="https://drive.google.com/file/d/1bj2bCJ2E5OCUky7gxqRYIBp5caqqu3Yc/view?usp=sharing">Demo 1</a> on numpy and working with arrays and plots (not turned in).
                                    </li>
                                    <li>
                                        Work through simple regression example in <a href="https://drive.google.com/file/d/1m80YJD6erWkS876KA6gVrt6gX3J9gz0e/view?usp=sharing">Demo 2</a>.
                                    </li>
                                    <li>
                                        Complete <a href="https://drive.google.com/file/d/17rhvdWcpASKM3rUBe513l4cxTWQxqGXa/view?usp=sharing">Lab 1</a>. Due <b>11:59pm, Thursday 2/3</b>.
                                   </li>        
                                </ul> 
                            </td>
                        </tr>
                        
                        <tr class="evenrow">
                            <th scope="row">2. 2/3</th>
                            <td>Multiple Linear Regression, Data Transformations, Model Selection, Regularization</td>
                            <td>                                
                                <ul>
                                    <li>
                                        <a href="./lectures/lec2.pdf">Lecture 2 slides</a> 
                                        <a href="./lectures/lec2_annotated.pdf">(annotated)</a>. 
                                    </li>
                                    <li>
                                        <a href="./lectures/gradient_practice.pdf">Notes on computing gradients.</a> <a href="./lectures/gradient_practice.md">(raw markdown)</a>.
                                    </li>      
                                    <li>
                                        For additional reading, see Chapter 3.2 in <b>An Introduction to Statistical Learning.</b>
                                    </li>                   

                                    <!-- <li>
                                        Caltech  <a href="https://work.caltech.edu/lectures.html#lectures">Lecture 12</a> on regularization. It might be helpful to watch the video for Lecture 8 first to understand what he means by "bias-variance" tradeoff (which we did not cover formally).
                                    </li> -->
                                    <!-- <li>
                                        Work through polynomial regression demo: <a href="https://github.com/cpmusco/introml/tree/master/model_selection_regularization"><code>demo_polyfit.ipynb</code></a>.
                                    </li> -->
                                </ul>
                            </td>
                            <td>
                                <ul>
                                    <li>
                                        Complete written <a href="./homeworks/hw1.pdf">Homework 1</a>. Due <b>11:59pm, Thursday 2/10</b>. 10% bonus if you typeset solutions in Markdown or Latex!
                                     </li>  
                                     <li>
                                        Work through additional numpy matrix demo: <a href="https://drive.google.com/file/d/1c2T5sE3BEq9K-NERwQj7S-kiPgTseZl1/view?usp=sharing"><code>demo_numpy_matrices.ipynb</code></a>.
                                    </li>
                                     <li>
                                        Work through multiple linear regression demo in <a href="https://drive.google.com/file/d/1SkYtF50TWnHGJBetrdEWSG9KEvIn-Djd/view?usp=sharing"><code>demo_diabetes.ipynb</code></a>.
                                    </li>  
                                    <li>
                                        For Homework 1, it might be helpful to check your answer for Problem 4 using an approach similar to the one I implement here in <a href="https://drive.google.com/file/d/1OjJFbyn59kxIIbAtAGRYZ6bv1RCgerC7/view?usp=sharing"><code>gradient_demo.ipynb</a>
                                    </li>
                                </ul>
                                <!-- <ul>
                                    <li>
                                        Complete Lab 2, <a href="https://github.com/cpmusco/introml/tree/master/multiple_linear_regression"><code>lab_robot_partial.ipynb</code></a>. Due <b>11:59pm, Tuesday 2/11</b>.
                                   </li>
                                   <li>
                                    Complete written <a href="https://github.com/cpmusco/introml/tree/master/multiple_linear_regression">Homework 2</a>. Due <b>11:59pm, Tuesday 2/18</b>.
                                    </li>
                                    <li>
                                    Complete Lab 3, <a href="https://github.com/cpmusco/introml/tree/master/model_selection_regularization"><code>lab_neural_partial.ipynb</code></a>. Due <b>11:59pm, Thursday 2/20</b>.
                               </li>
                                </ul> -->
                            </td>
                        </tr>

                        <tr class="oddrow">
                            <th scope="row">3. 2/10</th>
                            <td>Finish model selection, Regularization, Start Bayesian Perspective</td>
                            <td>                                
                                <ul>
                                    <li>
                                        <a href="./lectures/lec3.pdf">Lecture 3 slides</a> 
                                        <a href="./lectures/lec3_annotated.pdf">(annotated)</a>.
                                    </li>
                                    <li>
                                        <b>Additional reading on feature selection</b>: Chapter 6.1 in AISL.                              
                                    <li>
                                        <b>Additional reading on regularization</b>: Chapter 6.2 in AISL.
                                    </li>    
                                </ul>
                            </td>
                            <td>
                                <ul>
                                    <li>
                                        Work through polynomial model selection demo: <a href="https://drive.google.com/file/d/14t8adWkQOmQ8YljRl7sXFLCXH-3NQvdH/view?usp=sharing"><code>demo_polyfit.ipynb</code></a>.
                                    </li>
                                    <li>
                                        Complete <a href="https://drive.google.com/file/d/1ANbuRQLJ8_n-50oe7SeveVzb_MGT43eS/view?usp=sharing3">Lab 2.1</a>. Due <b>11:59pm, Friday 2/18</b>.
                                   </li>
                                   <li>
                                        Complete Lab 2.2, <a href="https://drive.google.com/file/d/1wp8jSl4ow9ONFz06L-ZMlKg-JwgF-tXQ/view?usp=sharing">Lab 2.2</a>. Due <b>11:59pm, Friday 2/18</b>.
                                    </li>
                                </ul>
                            </td>
                        </tr>


                        <tr class="evenrow">
                            <th scope="row">4. 2/17</th>
                            <td>Naive Bayes, the Bayesian Perspective</td>
                            <td>
                                <ul>
                                    <li>
                                        <a href="./lectures/lec4.pdf">Lecture 4 slides</a> 
                                        <a href="./lectures/lec4_annotated.pdf">(annotated)</a>.
                                    </li>   
                                    <li>
                                        <a href="./lectures/naive_bayes_extra.pdf">Additional lecture notes</a> on the Naive Bayes Algorithm.
                                    </li>   
                                    <li>
                                        Section 3 of <a href="http://cs229.stanford.edu/notes2019fall/cs229-notes1.pdf">these notes</a> gives a nice overview of least squares regression from a statistical/probabilistic modeling perspective. Also see section on logistic regression.
                                    </li>   
                                </ul>
                            </td>
                            <td>
                                <ul>
                                    <li>
                                        Work through logistic regression demo: <a href="https://drive.google.com/file/d/1zNH-5mpIHZ58BAJ9WFAivMraFGrvROPD/view?usp=sharing"><code>demo_breast_cancer.ipynb</code></a>.
                                    </li>
                                    <li>
                                        Complete written <a href="./homeworks/hw2.pdf">Homework 2</a>. Due <b>11:59pm, Monday 2/28</b>. Problem 3 requires completing the code stub at <a href="https://drive.google.com/file/d/1-W9O-c2eEQcfFkxhGYcpEdDG_efT7hGh/view?usp=sharing"><code>hw2_stub.ipynb</code></a>
                                     </li>  
                                </ul>
                            </td>
                        </tr>    


                        <tr class="tablesection">
                                <td colspan="4">Classification</td>
                        </tr>

                        <tr class="evenrow">
                                <th scope="row">5. 2/24</th>
                                <td>Linear Logistic Regression, Optimization, Gradient Descent</td>
                                <td>     
                                    <ul>                                          
                                        <li>
                                            <a href="./lectures/lec5.pdf">Lecture 5 slides</a> 
                                            <a href="./lectures/lec5_annotated.pdf">(annotated)</a>. I filled in the proofs on pages 46 and 47 for convexity of the least squares loss.
                                        </li>   
                                        <li>
                                            Notes on <a href="./lectures/logistic_regression_gradient.pdf">computing the gradient for logistic regression</a> (optional to review).
                                        </li>
                                    </ul>
                                </td>
                                <td>
                                </td>
                        </tr>

                        <tr class="oddrow">
                            <th scope="row">6. 3/3</th>
                            <td>Optimization, Gradient Descent, Stochastic Gradient Descent</td>
                            <td>
                                <!-- <ul>
                                    <li>
                                        <a href="./lectures/lec10.pdf">Lecture 10 slides</a> <a href="./lectures/lec10_annotated.pdf">(annotated)</a>.
                                    </li>
                                    <li>
                                        Notes on <a href="./lectures/logistic_regression_gradient.pdf">computing the gradient for logistic regression</a> (optional to review).
                                    </li>
                                    <li>
                                        <a href="./lectures/lec11.pdf">Lecture 11 slides</a> <a href="./lectures/lec11_annotated.pdf">(annotated)</a>.
                                    </li>
                                    <li>                          
                                        For information on the exam details, structure, and topics covered, consult <a href="./midterm1/midterm1_info.pdf">Midterm 1 information</a>.
                                    </li>
                                    <li>                          
                                        Here are some <a href="./midterm1/midterm1_sample_questions.pdf">sample questions</a> which will be similar to those on the exam. And some quick <a href="./midterm1/midterm1_sample_questions_solutions.pdf">solutions</a>
                                    </li>
                                </ul>     -->
                            </td>
                            <td></td>
                        </tr>

                        <tr class="evenrow">
                            <th scope="row">7. 3/10</th>
                            <td> 
                                <b>Midterm Exam</b> (first half of class)
                                <br>
                                <br>
                                
                                Learning Theory, Uniform Convergence, the PAC model
                            </td>
                            <td>
                            </td>
                            <td>
                            </td>
                        </tr>


                        <tr class="offday oddrow">
                            <th scope="row">3/17</th>
                            <td>Spring break, no class.</td>
                            <td></td>
                            <td></td>
                        </tr>

                        
        

                        <tr class="tablesection">
                            <td colspan="4">Beyond Linear Methods</td>
                        </tr>

                        <tr class="oddrow">
                            <th scope="row">8. 3/24</th>
                            <td>k-Nearest Neighbors, Kernel Method, Support Vector Machines</td>
                            <td>
                                <!-- <ul>
                                    <li>
                                        <a href="./lectures/lec12.pdf">Lecture 12 slides</a> <a href="./lectures/lec12_annotated.pdf">(annotated)</a>.
                                    </li>
                                    <li>
                                        <a href="./lectures/lec13.pdf">Lecture 13 slides</a> <a href="./lectures/lec13_annotated.pdf">(annotated)</a>.
                                    </li>
                                    <li>
                                        <a href="./lectures/lec14.pdf">Lecture 14 slides</a> <a href="./lectures/lec14_annotated.pdf">(annotated)</a>.
                                    </li>
                                    <li>
                                        Work through SVM demo:  <a href="https://github.com/cpmusco/introml/tree/master/support_vector_machines"><code>demo_mnist_svm.ipynb</code></a> 
                                    </li>
                                </ul>    -->
                            </td>
                            <td>
                                <!-- <ul>
                                    <li>
                                        Complete Lab 5, <a href="https://github.com/cpmusco/introml/tree/master/gradient_descent/"><code>lab_grad_descent_partial.ipynb</code></a>. Due <b>11:59pm, Thurs. 4/2</b>.
                                    </li>
                                    <li>
                                        The first half of this lab is a demo, which you should go through slowly. The parts you actually have to fill in don't start until the "L2 Regularization" section.
                                    </li>
                                </ul> -->
                            </td>
                        </tr>


                        <tr class="evenrow">
                            <th scope="row">9. 3/31</th>
                            <td>Neural Networks 1: Introduction, History</td>
                            <td>                                
                                <!-- <ul>
                                    <li>
                                        <a href="./lectures/lec15.pdf">Lecture 15 slides</a>  <a href="./lectures/lec15_annotated.pdf">(annotated)</a>.
                                    </li>
                                    <li>
                                        Make sure Tensorflow v2 is installed in your Python environment (already installed in Collab).
                                    </li>
                                    <li>
                                        Spend 30 mins or so messing around with <a href="https://playground.tensorflow.org/">playground.tensorflow.org</a> to build some intuition for working with neural nets!
                                    </li>
                                    <li>
                                        <a href="./lectures/lec16.pdf">Lecture 16 slides</a> <a href="./lectures/lec16_annotated.pdf">(annotated)</a>.
                                    </li>
                                </ul>  -->
                            </td>
                            <td>
                                <!-- <ul>
                                    <li>
                                        Complete Lab 6, <a href="https://github.com/cpmusco/introml/tree/master/support_vector_machines/"><code>lab_mnist_partial.ipynb</code></a>. Due <b>11:59pm, Thurs. 4/9</b>.
                                    </li>
                                </ul> -->
                            </td>
                        </tr>

                        <tr class="oddrow">
                            <th scope="row">10. 4/7</th>
                            <td>Neural Networks 2: Backpropagation, Stochastic Gradient Descent</td>
                            <td>
                                <!-- <ul>
                                    <li>
                                        <a href="./lectures/lec17.pdf">Lecture 17 slides</a> <a href="./lectures/lec17_annotated.pdf">(annotated)</a>.
                                    </li>
                                </ul>  -->
                            </td>
                            <td>                                
                                <!-- <ul>
                                    <li>
                                        Work through Keras neural network demo on synthetic data:  <a href="https://github.com/cpmusco/introml/tree/master/neural_nets"><code>keras_demo_synthetic.ipynb</code></a> 
                                    </li>
                                    <li>
                                        Work through Keras neural network demo on MNIST data:  <a href="https://github.com/cpmusco/introml/tree/master/neural_nets"><code>keras_demo_mnist.ipynb</code></a> 
                                    </li>
                                </ul>  -->
                            </td>
                        </tr>

                        <tr class="evenrow">
                            <th scope="row">11. 4/14</th>
                            <td>Convolution, Feature Extraction, Edge Detection, Feature Transfer</td>
                            <td>
                                <!-- <ul>
                                    <li>
                                        <a href="./lectures/lec18.pdf">Lecture 18 slides</a>  <a href="./lectures/lec18_annotated.pdf">(annotated)</a>.
                                    </li>
                                    <li>
                                        Work through demo on convolution:  <a href="https://github.com/cpmusco/introml/tree/master/convolutional_nets"><code>demo_convolutions.ipynb</code></a> 
                                    </li>
                                    <li>
                                        <a href="./lectures/lec19.pdf">Lecture 19 slides</a> <a href="./lectures/lec19_annotated.pdf">(annotated)</a>.
                                    </li>
                                </ul>  -->
                            </td>
                            <td>
                                <!-- <ul>
                                    <li>
                                        Complete written <a href="https://github.com/cpmusco/introml/tree/master/support_vector_machines">Homework 4</a>. Due <b>11:59pm, Monday 4/20</b>.
                                   </li>
                                   <li>
                                    Work through demo on convolutional networks for image classification:  <a href="https://github.com/cpmusco/introml/tree/master/convolutional_nets"><code>demo_classification.ipynb</code></a> 
                                    </li>
                                    <li>
                                    You will want to run this demo on a machine with GPU access. Probably the simplest option is to use Google Colab!
                                    </li>
                                </ul> -->
                            </td>
                        </tr>

                        <tr class="tablesection">
                            <td colspan="4">Unsupervised Learning</td>
                        </tr>

                        <tr class="oddrow">
                            <th scope="row">12. 4/21</th>
                            <td>Auto-encoders, Dimensionality Reduction, Principal Component Analysis, Semantic Embeddings</td>
                            <td>
                                <!-- <ul>
                                    <li>
                                        <a href="./lectures/lec20.pdf">Lecture 20 slides</a> <a href="./lectures/lec20_annotated.pdf">(annotated)</a>.
                                    </li>
                                    <li>
                                        <a href="./lectures/lec21.pdf">Lecture 21 slides</a> <a href="./lectures/lec21_annotated.pdf">(annotated)</a>.
                                    </li>
                                    <li>
                                        Check out this <a href="https://junyanz.github.io/CycleGAN/">research project</a> to get a sense of some of the amazing things people are doing in generative ML.
                                    </li>
                                    <li>
                                        If you have not seen lossless compression in a class before, I strongly recommend you watch a  <a href="https://www.khanacademy.org/computing/computer-science/informationtheory/moderninfotheory/v/compressioncodes">video on Huffman coding</a> to give you a better sense of how it works. Data compression is a super interesting and practically important topic in CS! 
                                    </li>
                                    <li>
                                        <a href="./lectures/lec22.pdf">Lecture 22 slides</a> <a href="./lectures/lec22_annotated.pdf">(annotated)</a>.
                                    </li>
                                </ul>  -->
                            </td>
                            <td></td>
                        </tr>
                        <!-- <tr class="evenrow">
                            <th scope="row">13. 4/21</th>
                            <td>Semantic Embeddings, Clustering</td>
                            <td>
                                <!-- <ul>
                                    <li>
                                        <a href="./lectures/lec23.pdf">Lecture 23 slides</a> <a href="./lectures/lec23_annotated.pdf">(annotated)</a>.
                                    </li>
                                </ul> -->
                            </td>
                            <td></td>
                        </tr> -->

                        <tr class="tablesection">
                            <td colspan="4">Selected Topics</td>
                        </tr>

                        <tr class="evenrow">
                            <th scope="row">13. 4/28</th>
                            <td>Introduction to Reinforcement Learning</td>
                            <td>  
                                <!-- <ul>
                                    <li>
                                        <a href="./lectures/lec24.pdf">Lecture 24 slides</a> <a href="./lectures/lec24_annotated.pdf">(annotated)</a>.
                                    </li>
                                </ul> -->
                            </td>
                            <td>
                                <!-- <ul>
                                    <li>
                                        <a href="https://www.youtube.com/watch?v=lvoHnicueoE">Stanford lecture on Q-learning</a>.
                                    </li>
                                    <li>
                                        <a href="https://www.youtube.com/watch?v=V1eYniJ0Rnk">Reinforcement learning demonstration</a>.
                                    </li>
                                </ul> -->
                            </td>
                        </tr>

                        <tr class="oddrow">
                            <th scope="row">14. 5/5</th>
                            <td>TBA</td>
                            <td>  
                            </td>
                            <td>
                            </td>
                        </tr>

                    </tbody>
                </table>

            </div>
        </div>

    </main>

    <!-- <footer class="container">
        <p>&copy 2017-2018</p>
    </footer> -->

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="js/jquery-3.3.1.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
</body>

</html>